---
title: "Formation R Perfectionnement"
fontsize: 12pt
output:
  html_document:
    fig.retina: 1.75
    highlight: haddock
    toc: yes
    toc_depth: 2
    toc_float: yes
    includes:
      in_header: header.html
      before_body: before_body.html
  pdf_document:
    highlight: haddock
    keep_tex: yes
header-includes: 
  \usepackage[french]{babel}
  \addto\captionsfrench{\renewcommand{\contentsname}{}}
  \setcounter{tocdepth}{1} \usepackage{framed} 
  \definecolor{shadecolor}{RGB}{248,248,248}
geometry: margin=2.5cm
documentclass: article
---

```{r, include=FALSE, cache=FALSE}
knitr::opts_knit$set(root.dir = "../../donnees/#output_perf")
knitr::opts_chunk$set(collapse = TRUE, cache=TRUE)
.numQuestion <- 0L
.numHide <- 0L
.html <<- knitr::opts_knit$get("rmarkdown.pandoc.to") == "html"
.pdf <<- knitr::opts_knit$get("rmarkdown.pandoc.to") == "latex"
.question <- function(text = NULL){
  .numQuestion <<- .numQuestion + 1L
  cat("\n"); cat("\\ \n"); cat("\n");
  cat("#### **Cas pratique ",.numQuestion, "** ", text, sep = "")
}

# Solution d'une question
.beginsol <- function(){
  .numHide <<- .numHide + 1L
  if(.html){
    cat("<div style = \"text-align: right;\">")
    cat("<button type=\"button\" onclick=\"hide('sol", .numHide, "')\">Afficher/masquer la solution</button>", sep = "")
    cat("</div>")
    cat("<div id='sol", .numHide, "' style=\"display: none; height: 0;\">\n<hr/>", sep = "")
  }
  if(.pdf) cat("\\ifsol \n \\begin{center} \\rule{0.5\\linewidth}{\\linethickness}\\end{center} \n")
}
.endsol <- function(){
  if(.html) cat("\n<hr /></div>\n\n \\ \n \n")
  if(.pdf) cat("  \n  \\begin{center} \\rule{0.5\\linewidth}{\\linethickness}\\end{center} \n \\bigskip \n \\fi \n")
}

# Indication d'une question
.indic <- function(text){
  .numHide <<- .numHide + 1L
  if(.html){
    cat("<div style = \"text-align: right;\">")
    cat("<button type=\"button\" onclick=\"hide('sol", .numHide, "');this.style.display='none'\">Indication</button>", sep = "")
    cat("</div>")
    cat("<div id='sol", .numHide, "' style=\"display: none; height: 0;\">\n", sep = "")
    cat(text)
    cat("\n</div>\n\n \\ \n \n")
  }
  if(.pdf){
    cat("\\ifsol \n")
    cat(text)
    cat("\\fi \n")
  }
}

```

Cette page comporte l'ensemble des cas pratiques de la formation R perfectionnement donnée à la Drees les 16 et 17 avril 2018 accompagnés de leur correction. 

- [Support de présentation](presentation_handout.pdf)
- [Données utilisées dans les cas pratiques](donnees.zip)

Les supports de cette formation ont été conçus sous RStudio avec [R Markdown](http://rmarkdown.rstudio.com/) et compilés le `r format(Sys.Date(), format="%d/%m/%Y")`. Certains éléments de mise en forme du site compagnon sont repris de l'ouvrage [R packages](http://r-pkgs.had.co.nz/) de Hadley Wickham. 
  
Ces supports seront durablement disponibles à l'adresse [http://   t.slmc.fr/perf](http://t.slmc.fr/perf/) et leur code source sur [github](https://github.com/martinchevalier/r_insee). L'ensemble est librement réutilisable sous &copy;\ 2016-2018 Martin Chevalier [CC BY-NC-SA 3.0](https://creativecommons.org/licenses/by-nc-sa/3.0/fr).


## Savoir utiliser les fonctions `*apply()`, `do.call()` et `Reduce()`

Le *package* `microbenchmark` est souvent utilisé dans cette partie et les suivantes pour mesurer la performance des des  solutions testées :
```{r, eval = FALSE}
install.packages("microbenchmark")
library(microbenchmark)
```

```{r, include = FALSE}
library(microbenchmark)
```

```{r, results = "asis", echo = FALSE, cache=FALSE, cache=FALSE}
.question("Fonctions et environnements")
```
Tout ce qui se passe dans R correspond à un appel de fonction. Comprendre le fonctionnement des fonctions et savoir en créer soi-même est donc crucial. 

a. Utilisez les guillemets simples inversés (AltGr + 7 sur le clavier azerty) pour afficher le code associé au signe `+`. Utilisez-le comme une fonction classique avec la syntaxe `nomFonction(parametre1, parametre2)`. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# Pour afficher le code d'une fonction, il suffit
# de saisir son nom. Dans le cas des signes 
# arithmétiques, il convient d'entourer le nom
# de guillemets inversés
`+`
    
# En utilisant les guillemets inversés, on peut
# utiliser la fonction `+`() comme n'importe
# quelle fonction (en appelant ses arguments dans
# la parenthèse).
`+`(2, 2)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```


b. Définissez la fonction `monCalcul(x, puissance)` qui pour un vecteur numérique `x` quelconque : 

    1. calcule sa somme ; 

    2. met la somme à la puissance `puissance`. 

    Dans un second temps, donnez à `puissance` la valeur `2` par défaut et faites en sorte que la fonction prenne en charge les vecteurs `x` présentant des valeurs manquantes `NA`.


    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# Associée à `<-`, la fonction function()
# permet de définir une nouvelle fonction
monCalcul <- function(x, puissance){
  resultat <- sum(x)^puissance
  return(resultat)
}
monCalcul(1:3, puissance = 2)

# La syntaxe suivante est équivalente : 
monCalcul <- function(x, puissance) sum(x)^puissance
monCalcul(1:3, puissance = 2)

# Pour ajouter un argument par défaut, il suffit 
# de le spécifier dans la parenthèse de function()
monCalcul <- function(x, puissance = 2) sum(x)^puissance
monCalcul(1:3)

# L'argument na.rm = TRUE de la fonction sum()
# permet d'exclure automatiquement les valeurs manquantes.
monCalcul <- function(x, puissance = 2) sum(x, na.rm = TRUE)^puissance
monCalcul(c(1:3, NA))
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

c. Modifier la fonction pour ajouter une étape de vérification du type de `x` : prévoyez un message d'erreur si `x` est de type `character` ou `factor`. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r, error = TRUE}
# Les fonctions is.character() et is.factor() permettent
# de tester le type de x. 
monCalcul <- function(x, puissance = 2){
  if(is.character(x) || is.factor(x)) stop("x est de type caractère ou factor.")
  sum(x, na.rm = TRUE)^puissance
}
monCalcul(c("a", "c"))
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

d. Quelle est la valeur de l'objet `T` ? Comment expliquez-vous que cet objet soit défini alors que vous ne l'avez pas vous-même créé (vous pouvez utiliser la fonction `getAnywhere()` pour répondre) ?

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# L'objet T a par défaut la valeur TRUE
T

# T est défini dans le package base de R comme un alias de TRUE
getAnywhere(T)
base::T
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```
e. Soumettez le code `T <- 3`. Que vaut désormais l'objet `T` ? Pourquoi R n'accède-t-il plus à la valeur stockée par défaut (vous pouvez utiliser la fonction `search()` pour répondre) ? Comment accéder désormais à la valeur par défaut ? Que retenez-vous quant à l'utilisation de `T` et de `F` en lieu et place de `TRUE` et `FALSE` dans un code ? 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
T <- 3
T 
# R accède en premier lieu à l'environnement global, puis
# aux packages dans l'ordre de search()
search()
# Le package base est situé en dernière position.

# Pour accéder explicitement à l'élément du package base,
# on utilise ::
base::T

# Le fait que T et F ne soit que des alias pour TRUE et FALSE
# et donc que leur valeur soit modifiable invite à la plus
# grande prudence dans leur utilisation. Elle est en fait
# à proscrire dans la réalisation de projets importants 
# (par exemple l'écriture d'un package).
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("`apply()` : Appliquer une fonction selon les dimensions d'une matrice")
```

a. Créez une matrice `e1` de 3 lignes et de 5 colonnes en utilisant la fonction `runif()`. Ses valeurs sont-elles identiques si vous la générez une seconde fois ? Comment faire pour que cela soit le cas ? 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# Par défaut,  l'utilisation sucessive de la fonction
# runif() ne conduit pas aux mêmes résultats
e1 <- matrix(runif(15), ncol = 5)
e1
e1b <- matrix(runif(15), ncol = 5)
e1b
identical(e1, e1b)

# La fonction set.seed() permet en revanche d'initialiser
# le générateur de nombres pseudo-aléatoires de R. 
# Utilisé après la fonction set.seed(), deux fonctions
# runif() donneront toujours le même résultat.
set.seed(2016)
e1 <- matrix(runif(15), ncol = 5)
e1
set.seed(2016)
e1b <- matrix(runif(15), ncol = 5)
e1b
identical(e1, e1b)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

b. Utilisez la fonction `apply()` pour calculer la somme des termes de chaque ligne de `e1`. Comment auriez-vous pu faire autrement ? Utilisez la fonction `microbenchmark()` pour comparer ces deux solutions. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# La fonction apply() permet d'appliquer
# une même fonction aux lignes ou aux colonnes
# d'une matrice. 
apply(e1, 1, sum)
# Le second argument indique la dimension selon
# laquelle appliquer la fonction (1 pour les lignes, 
# 2 pour les colonnes). 
    
# Cette opération est en fait nativement implémentée
# via la fonction rowSums()
rowSums(e1)

# La fonction microbenchmark() permet de comparer
# systématiquement ces deux stratégies (apply() ou
# rowSums())
microbenchmark(times = 1e4
  , apply = apply(e1, 1, sum)
  , rowSums = rowSums(e1)
)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

c. Utilisez la fonction `apply()` pour centrer-réduire toutes les colonnes de `e1` (*i.e.* leur soustraire leur moyenne puis les diviser par leur écart-type).

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# Etape 1 : fonction pour centrer-réduire une variable
x <- runif(10)
mean(x) # Moyenne de x
sd(x) # Ecart-type de x
centrer_reduire <- function(x) ( x - mean(x) ) / sd(x)
z <- centrer_reduire(x)
mean(z)
sd(z)

# Etape 2 : utilisation dans un apply()
e2 <- apply(e1, 2, centrer_reduire)
colMeans(e2)
apply(e2, 2, sd)

# Tout en une seule étape :
e3 <- apply(e1, 2, function(x) ( x - mean(x) ) / sd(x))
identical(e2, e3)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```
    
   
```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("`lapply()` et `sapply()` : Appliquer une fonction aux éléments d'un vecteur, d'une liste ou aux colonnes d'un data.frame")
``` 

a. On définit le vecteur `f1` par `f1 <- 5:15`. Utilisez la fonction `sapply()` pour calculer la somme cumulée des éléments de `f1`. Quelle(s) alternative(s) envisageriez-vous ? Utilisez la fonction `microbenchmark()` pour comparer ces solutions. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# INDICATION : commencer par définir la fonction 
# sumfirst(x, i) qui calcule la somme des i premiers 
# éléments de x, puis utilisez-la dans un sapply(). 
    
f1 <- 5:15
    
# Méthode 1 : sapply()
# L'objectif est d'obtenir un vecteur de longueur length(f1)
# qui pour chaque élément i renvoie la somme des éléments 1 à i
# de f1

# Pour calculer la somme des 4 premiers termes, il suffit d'appliquer
# la fonction sum() au vecteur f1 restreint à ses 4 premiers termes
sum(f1[1:4])

# On généralise cette idée dans un sapply() en définissant
# la fonction à la volée (x remplace ici le 4 de l'exemple)
sapply(1:length(f1), function(i) sum(x[1:i]))
# Note : dans cette méthode pour chaque élément du vecteur
# on recalcule la somme, sans réutiliser celle calculée
# pour les éléments précédents.

# Remarque : on peut aussi utiliser la fonction
# seq_along() pour créer le vecteur d'indices
sapply(seq_along(f1), function(i) sum(x[1:i]))



# Méthode 2 : cumsum()
# La fonction cumsum() effectue nativement cette opération
cumsum(f1)

# Comparaison avec microbenchmark()
microbenchmark(times = 1e4
  , sapply = sapply(seq_along(f1), function(i) sum(f1[1:i]))
  , cumsum = cumsum(f1)
)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

b. On définit la liste `f2` par 
    ```{r}
f2 <- list(
  sample.int(26, 10, replace = TRUE)
  , sample.int(26, 100, replace = TRUE)
  , sample.int(26, 1000, replace = TRUE)
)
    ```

Utilisez les fonctions `lapply()` ou `sapply()` pour : 

  - retrouver la longueur de chacun des éléments de `f2` ;
  - extraire les 5 premiers éléments de chacun des éléments de `f2` ;
  - remplacer chaque élément de `f2` par le vecteur de lettres (en minuscules) dont il représente les positions dans l'alphabet.

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# Les fonctions sapply() et lapply() permettent 
# d'appliquer systématiquement une fonction aux éléments
# d'une liste. 
    
# Pour connaître la longueur de chaque élément de f2, 
# il suffit ainsi d'appliquer à chacun la fonction length()
lapply(f2, length)
    
# sapply() effectue exactement le même traitement que
# lapply() mais essaie en plus de simplifier le résultat
# si c'est possible
sapply(f2, length)
# Ici c'est le cas : on passe d'une liste avec lapply()
# à un vecteur avec sapply()
    
# Pour extraire les éléments 1 à 10 de chacun des éléments
# de f2, on utilise l'opérateur [
lapply(f2, function(x) x[1:10])
# On aurait aussi pu soumettre de façon équivalente 
lapply(f2, `[`, 1:10)
# car x[1:10] est équivalent à `[`(x, 1:10)

# Remplacer les éléments d'un des éléments de f2
# par les lettres dont il représente la position
# est relativement simple : 
letters[f2[[1]]]
# On reprend donc le principe de la sous-question
# précédente dans un lapply()
# lapply(f2, function(x) letters[x])
# (commenté ici pour ne pas saturer la sortie).
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

c. On définit le `data.frame` `f3` par 
    ```{r}
set.seed(1)
f3 <- data.frame(
  id = letters[1:20]
  , by = rep(letters[1:5], times = 4)
  , matrix(runif(100), ncol = 5)
  , stringsAsFactors = FALSE
)
    ```
Utilisez les fonctions `lapply()` ou `sapply()` pour : 

  - déterminer le type de chacune des variables de `f3`;
  - calculer la moyenne de toutes les variables numériques de `f3`;
  - convertir toutes les variables de type `character` en facteurs. 
    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# Un data.frame étant un cas particulier de liste, 
# on peut lui appliquer les fonctions lapply() et
# sapply() exactement comme on le ferait pour une liste.
    
# Pour connaître le type de chacun de ses éléments, 
# on leur applique donc systématiquement la fonction
# typeof()
sapply(f3, typeof)
    
# Pour appliquer une même fonction à toutes ses variables 
# de type numériques, on commence par les identifier
# avec un is.numeric() dans un sapply()
num <- sapply(f3, is.numeric)
num
# Puis on leur applique la fonction désirée
sapply(f3[num], mean)

# De même pour les variables de type caractère
char <- sapply(f3, is.character)
char
f3[char] <- lapply(f3[char], as.factor)
str(f3)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("`tapply()` : Appliquer une fonction selon les modalités d'un vecteur")
``` 

a. On définit le vecteur `g1 <- sample(20)` et le vecteur `g2 <- rep(c("H", "F"), times = 10)`. Utilisez `tapply()` pour calculer la moyenne  de `g1` selon les groupes définis par `g2`. 
    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
set.seed(2)
g1 <- sample(20)
g2 <- rep(c("H", "F"), times = 10)

# La fonction tapply() permet d'appliquer une fonction
# à un vecteur selon les modalités d'un autre vecteur
tapply(g1, g2, mean)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

b. On repart du `data.frame` `f3` du cas pratique précédent. Utilisez `tapply()` pour calculer le total de la variable `X1` selon les modalités de la variable `by`. 
    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# Il suffit d'utiliser tapply() sur les variables de f3
tapply(f3$X1, f3$by, sum)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

c. Combinez la fonction `split()` avec `sapply()` pour obtenir le même résultat. Comment calculeriez-vous le total de toutes les variables numériques de `f3` selon les modalités de la variable `by` ? 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# La fonction split() éclate en une liste un vecteur 
# ou un data.frame selon les modalités d'une ou plusieurs
# variables.
f3[,c("by", "X1")]
split(f3$X1, f3$by)

# Ce faisant, on peut avec une fonction lapply()
# ou sapply() reproduire le comportent de la fonction
# tapply()
sapply(split(f3$X1, f3$by), sum)

# L'avantage de cette technique est qu'elle
# permet d'appliquer le même type de traitement
# non à une seule variable mais à plusieurs
# d'un seul coup
sapply(split(f3[num], f3$by), function(x){
  sapply(x, sum)
})
# ... ou de façon équivalente (mais un peu difficile
# à relire !)
sapply(split(f3[num], f3$by), sapply, sum)
# ... ou plus efficacement avec colSums()
sapply(split(f3[num], f3$by), colSums)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```



```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("`do.call()` : Appliquer une fonction simultanément à l'ensemble des éléments d'une liste")
```
De nombreuses fonctions peuvent porter sur un nombre indéterminé d'éléments : `c()`, `sum()`, `rbind()`, etc. Pour les appliquer à l'ensemble des éléments d'une liste sans avoir à tous les écrire un à un, il suffit d'utiliser `do.call()`. 


a. On définit la liste `h1 <- list(1:5, 6:10, 11:15)`. 
Que se passe-t-il si vous soumettez `sum(h1)` ? Utilisez `do.call()` pour sommer l'ensemble des éléments de `h1`. Comparez avec le résultat de `sapply(h1, sum)`. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r, error = TRUE}
h1 <- list(1:5, 6:10, 11:15)
    
# La fonction sum() ne peut pas porter sur une liste
sum(h1)

# En revanche, il est possible d'appliquer la fonction
# sum() à l'ensemble des éléments de h1
sum(h1[[1]], h1[[2]], h1[[3]])

# Pour automatiser cette expression, on peut utiliser
# do.call()
do.call(sum, h1)

# A l'inverse, sapply(h1, sum) applique la fonction
# sum() à chaque élément de h1 : 
sapply(h1, sum)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```


b. Réunissez les éléments de `h1` en un seul vecteur avec la fonction `base::c()`. Comparez avec le résultat de `lapply(h1, base::c)`

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# La fonction base::c() permet de concaténer
# les vecteurs qui constituent h1 
c(h1[[1]], h1[[2]], h1[[3]])
    
# Pour automatiser cette expression, on peut utiliser
# do.call()
do.call(base::c, h1)
# Note : on utilise ici base::c pour bien indiquer que
# c'est la fonction c() du package base que l'on 
# souhaite utiliser. En effet, si l'on avait défini
# on objet c dans l'environnement global il y aurait
# eu un conflit de noms.

# lapply(h1, base::c) applique la fonction base::c()
# à chaque élément de h1, ce qui ne change rien
lapply(h1, base::c)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```


c. On définit la liste de matrices `h2`
    ```{r}
h2 <- list(
  matrix(1:6, nrow = 2)
  , matrix(7:12, nrow = 2)
  , matrix(13:18, nrow = 2)
)
    ```
Utilisez `do.call()` avec les fonctions `rbind()` et `cbind()` pour concaténer l'ensemble des éléments de `h2` en ligne ou en colonne respectivement.
    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# Pour concaténer les éléments de h2 en ligne, 
# on utilise rbind()
rbind(h2[[1]], h2[[2]], h2[[3]])
    
# Pour automatiser cette expression, on peut utiliser
# do.call()
do.call(rbind, h2)

# De même en colonne avec cbind()
do.call(cbind, h2)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```




```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("`Reduce()` : Appliquer une fonction successivement à l'ensemble des éléments d'une liste")
```
De nombreuses fonctions portent sur deux éléments précisément : opérations arithmétiques, `merge()`, etc. Pour les appliquer successivement à l'ensemble des éléments d'une liste, il suffit d'utiliser `Reduce()`. 


a. On repart de la liste `h1` du cas pratique précédent. Observez le résultat de  ``Reduce(`+`, h1)`` : comment le comprenez-vous ? Comparez avec `sapply(h1, sum)`.

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r, error = TRUE}
# Reduce(f, x) applique la fonction f() aux éléments de x
# 2 à 2 et successivement. 
Reduce(`+`, h1)
# Ici, cette expression est équivalente à 
( h1[[1]] + h1[[2]] ) + h1[[3]]
# Le vecteur obtenu est la somme terme à terme de 
# tous les éléments qui composent h1
    
# A l'inverse, sapply(h1, sum) applique la fonction
# sum() à chaque élément de h1 : 
sapply(h1, sum)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

b. On définit la liste de `data.frame` `i1`
    ```{r}
i1 <- list(
  data.frame(id = letters[1:4], var1 = 1:4, stringsAsFactors = FALSE)
  , data.frame(id = letters[2:5], var2 = 5:8, stringsAsFactors = FALSE)
  , data.frame(id = letters[3:6], var3 = 9:12, stringsAsFactors = FALSE)
)
    ```
Utilisez `Reduce()` pour fusionner l'ensemble des éléments de `i1` selon la variable `id`. Comment ajusteriez-vous ce code pour pouvoir utiliser l'option `all = TRUE` de la fonction `merge()` ? 
    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# La fonction Reduce() est particulièrement utile 
# pour fusionner de nombreux data.frame selon la
# même variable. Par défaut, la fonction merge()
# fusionne les data.frame sur les variables qu'ils
# ont en commun.
Reduce(merge, i1)
# Ce code fournit le résultat désiré. 
    
# Pour spécifier explicitement la variable de fusion, 
# il faut redéfinir à la volée la fonction à appliquer 
# dans le Reduce() (comme dans un *apply) : 
Reduce(function(x, y) merge(x, y, by = "id"), i1)

# De même pour ajouter d'autres options à la fonction 
# merge()
Reduce(function(x, y) merge(x, y, by = "id", all = TRUE), i1)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```


## Travailler efficacement sur des données avec base R

L'ensemble des cas pratiques qui suivent portent sur les données de l'enquête Emploi en continu stockées dans le fichier `eect4.rds`. La fonction `readRDS()` permet de le charger en mémoire : 
```{r, eval = FALSE}
setwd("Y:/Documentation/R/R_perfectionnement/donnees")
eec <- readRDS("eect4.rds")
str(eec)
```

```{r, echo = FALSE}
eec <- readRDS("eect4.rds")
str(eec)
```

```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("Sélection d'observations")
```

a. Utilisez l'opérateur `[` pour sélectionner l'individu appartenant au ménage dont l'`IDENT` est `"GFO5NVUE"` et dont le numéro d'ordre `NOI` est `"02"`. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# Il suffit de créer le vecteur logique correspondant
# et de l'utiliser das `[`
eec[eec$IDENT == "GFO5NVUE" & eec$NOI == "02", ]  
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

b. Cherchez de la documentation sur la fonction `subset()`. Comparez ses performances avec celles de l'opérateur `[` à l'aide de la fonction `microbenchmark()`. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# subset() permet d'évaluer une clause logique
# sans avoir à répéter le nom du data.frame
# d'origine
subset(eec, IDENT == "GFO5NVUE" & NOI == "02")
    
# Comparaison des performances
microbenchmark(times = 1e2
  , "[" = eec[eec$IDENT == "GFO5NVUE" & eec$NOI == "02", ]  
  , subset = subset(eec, IDENT == "GFO5NVUE" & NOI == "02")
)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

c. Concaténez les valeurs des variables `IDENT` et `NOI` et utilisez le résultat comme noms de ligne. Retrouvez alors l'individu de la question a à l'aide de son nom de ligne. Comparez les performances de cette méthode avec celles de l'opérateur `[`. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# La foncton paste0() permet de concaténer des chaînes
# de caractères sans utiliser de délimiteur
row.names(eec) <- paste0(eec$IDENT, eec$NOI)
    
# Sélection de l'individu par son nom de ligne
eec["GFO5NVUE02", ]

# Comparaison des performances
microbenchmark(times = 1e2
  , "[" = eec[eec$IDENT == "GFO5NVUE" & eec$NOI == "02", ]  
  , names = eec["GFO5NVUE02", ]
)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```


```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("Création de variables")
```
On souhaite recoder la variable `AGE` en trois modalités : 15-30 ans, 31-60 ans et plus de 60 ans. On part du code suivant : 
```{r, eval = FALSE}
for(i in 1:nrow(eec)) eec$trage1[i] <- if(as.numeric(eec$AGE[i]) < 31) "15-30" else if(as.numeric(eec$AGE[i]) < 61) "31-60" else "61 et +"
```

a. Mesurez le temps d'exécution du code proposé. Que pensez-vous de cette syntaxe ?

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# Mesure du temps d'exécution de cette première version
microbenchmark(times = 1
  , v1 = {
    for(i in 1:nrow(eec)) eec$trage1[i] <- if(as.numeric(eec$AGE[i]) < 31) "15-30" else if(as.numeric(eec$AGE[i]) < 61) "31-60" else "61 et +"
  }
)
# Remarques : 
# - on ne fait qu'une seule itération car le temps d'exécution 
# est très long (plusieurs secondes !).
# - le as.numeric() n'est pas indispensable mais accélère sensiblement
# le traitement en faisant en sorte que la comparaison par < s'effectue 
# entre vecteurs de type numérique et pas entre vecteurs de type caractère.

# Cette syntaxe présente un énorme problème : elle utilise
# une boucle là où des opérations vectorisées beaucoup 
# plus rapides sont disponibles.
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```
b. On propose une seconde version du code : 
    ```{r, eval = FALSE}
eec$trage2 <- ifelse(as.numeric(eec$AGE) < 31, "15-30", ifelse(
  as.numeric(eec$AGE) < 61, "31-60", "61 et +"
))
    ```
Vérifiez que le résultat est identique à la proposition initiale (par exemple avec `identical()`ou `all.equal()`) et mesurez le temps temps d'exécution de cette deuxième version. Êtes-vous surpris du gain de performances ? 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
eec$trage2 <- ifelse(as.numeric(eec$AGE) < 31, "15-30", ifelse(
  as.numeric(eec$AGE) < 61, "31-60", "61 et +"
))

# Vérification de la correspondance 
# avec la première version
all.equal(eec$trage1, eec$trage2)

# Comparaison des performances
microbenchmark(times = 1e1
  , v2 = {
    eec$trage2 <- ifelse(as.numeric(eec$AGE) < 31, "15-30", ifelse(
      as.numeric(eec$AGE) < 61, "31-60", "61 et +"
    ))
  }
)

# On n'est pas surpris du gain de performance : en R, 
# les boucles sont beaucoup moins efficaces que les 
# opérations vectorisées (qui reposent sur des 
# boucles dans des langages de plus bas niveau).
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```


c. Comment recoderiez-vous la proposition précédente pour ne plus faire appel à la fonction `ifelse()` ? Cela est-il susceptible d'améliorer les performances ? Mettez en oeuvre cette solution et mesurez-en les performances.

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# Il est possible de se passer de ifelse() en utilisant
# l'opérateur [ pour effectuer des remplacements successifs. 
eec$trage3 <- "15-30"
eec$trage3[as.numeric(eec$AGE) > 30 & as.numeric(eec$AGE) < 61] <- "31-60"
eec$trage3[as.numeric(eec$AGE) > 60] <- "61 et +"

# Vérification de la correspondance 
# avec la première version
all.equal(eec$trage1, eec$trage3)

# Comparaison des performances
microbenchmark(times = 1e1
  , v2 = {
    eec$trage2 <- ifelse(as.numeric(eec$AGE) < 31, "15-30", ifelse(
      as.numeric(eec$AGE) < 61, "31-60", "61 et +"
    ))
  }
  , v3 = {
    eec$trage3 <- "15-30"
    eec$trage3[as.numeric(eec$AGE) > 30 & as.numeric(eec$AGE) < 61] <- "31-60"
    eec$trage3[as.numeric(eec$AGE) > 60] <- "61 et +"
  }
)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```
d. Combien de fois appelez-vous la fonction `as.numeric()` dans le code qui précède ? Proposez une dernière version qui minimise les opérations effectuées par R et synthétisez le gain en termes de performances. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# La fonction as.numeric() est appelée trois fois dans
# le code qui précède. Pour gagner du temps, on
# crée la variable t temporaire que l'on utilise
# en lieu et place de as.numeric(eec$AGE)
t <- as.numeric(eec$AGE)
eec$trage4 <- "15-30"
eec$trage4[t > 30 & t < 61] <- "31-60"
eec$trage4[t > 60] <- "61 et +"

# Vérification de la correspondance 
# avec la première version
all.equal(eec$trage1, eec$trage4)


# Comparaison des performances
microbenchmark(times = 10
  , v2 = {
    eec$trage2 <- ifelse(as.numeric(eec$AGE) < 31, "15-30", ifelse(
      as.numeric(eec$AGE) < 61, "31-60", "61 et +"
    ))
  }
  , v3 = {
    eec$trage3 <- "15-30"
    eec$trage3[as.numeric(eec$AGE) > 30 & as.numeric(eec$AGE) < 61] <- "31-60"
    eec$trage3[as.numeric(eec$AGE) > 60] <- "61 et +"
  }
  , v4 = {
    t <- as.numeric(eec$AGE)
    eec$trage4 <- "15-30"
    eec$trage4[t > 30 & t < 61] <- "31-60"
    eec$trage4[t > 60] <- "61 et +"
  }
)

# Le passage de la version 1 à la version 4 du code s'est
# donc traduit par un gain en termes de performances
# de l'ordre d'un facteur 1 000.
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```




```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("Agrégation par groupes : salaire moyen par région")
```

On cherche à calculer le plus efficacement possible le salaire moyen (variable `SALRED`) par région (variable `REG`), d'abord sans pondérer puis en pondérant par le poids de sondage `EXTRI1613`. 

a. Comparez les performances des fonctions `aggregate()`, `by()`, `sapply()` (avec `split()`) et `tapply()` pour le calcul du salaire moyen **non-pondéré** par région.

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# INDICATION : consultez l'aide de chacune de ces fonctions
# pour vous approprier leur syntaxe.
    
# On adapte à chaque fonction la syntaxe à mettre en oeuvre
# et on compare leurs performances
microbenchmark(times = 10
  , aggregate = aggregate(eec$SALRED, list(eec$REG), mean, na.rm = TRUE)
  , by = by(eec$SALRED, eec$REG, mean, na.rm = TRUE)
  , sapply = sapply(split(eec$SALRED, eec$REG), mean, na.rm = TRUE)
  , tapply = tapply(eec$SALRED, eec$REG, mean, na.rm = TRUE)
)
# En règle générale sapply() et tapply() conduisent aux meilleures
# performances et sont proches l'une de l'autre. 
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

b. Quelles pistes envisageriez-vous pour améliorer encore les performances dans ce type de situation ? 
    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# Plusieurs pistes sont envisageables : 
# - utiliser des manipulations purement vectorielles ;
# - utiliser des manipulations matricielles sur des matrices lacunaires avec le package `Matrix`;
# - paralléliser l'exécution avec le package `parallel`; 
# - coder la fonction en C++.
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

c. Utilisez la fonction `sapply()` pour calculer le salaire moyen **pondéré** (par le poids de sondage `EXTRI1613`) par région. Y parvenez-vous également avec `tapply()` ? 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r, eval = FALSE}
# INDICATION 1 : appliquez la fonction split() à un objet
# contenant le salaire et le poids de sondage pour 
# pouvoir utiliser les deux variables dans le *apply(). 
# INDICATION 2 : vous pouvez calculer la moyenne pondérée
# "à la main" ou utiliser la fonction weighted.mean()

# Par rapport à la question a., la principale différence
# vient du fait que l'on a besoin de plusieurs éléments
# dans chaque bloc éclaté par la fonction split() : 
# le salaire d'une part, le poids de sondage d'autre part.
    
# Avec la fonction weighted.mean()
sapply(
  split(eec[c("SALRED", "EXTRI1613")], eec$REG)
  , function(x) weighted.mean(x$SALRED, x$EXTRI1613, na.rm = TRUE)
)
    
# Manuellement en pensant bien à exclure les poids de sondage
# des individus pour lesquels SALRED est NA
sapply(
  split(eec[c("SALRED", "EXTRI1613")], eec$REG)
  , function(x) sum(x$SALRED * x$EXTRI1613, na.rm = TRUE) / sum((!is.na(x$SALRED)) * x$EXTRI1613, na.rm = TRUE)
)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```


```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("Fusion de tables : nombre d'individus au chômage par ménage")
```

L'objectif de ce cas pratique est de créer, dans la table `eec`, une variable indiquant pour chaque individu le nombre d'individus au chômage dans son ménage. La position sur le marché du travail est codée par la variable `ACTEU` (`ACTEU == "2"` correspond au chômage) et l'identifiant du ménage est la variable `IDENT` (les individus d'un même ménage ont la même valeur pour la variable `IDENT`).  

a. Utilisez la fonction `tapply()` pour déterminer le nombre de personnes au chômage dans chaque ménage et stockez cette information dans un objet appelé `nbcho`. Quelles sont ses caractéristiques ?

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# Il suffit d'appliquer la fonction sum() par ménage 
# à l'indicatrice de chômage eec$ACTEU == 2
nbcho <- tapply(eec$ACTEU == "2", eec$IDENT, sum, na.rm = TRUE)
    
# Caractéristiques de nbcho
str(nbcho)
# nbcho est un vecteur nommé dont les noms sont 
# les identifiants de ménage.
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

b. Utilisez la fonction `merge()` pour refusionner le résultat de la question précédente avec la table `eec` et créer la variable `nbcho`. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# Etape 1 : constituer un data.frame à partir de nbcho 
# avec IDENT comme identifiant
nbcho_df <- data.frame(IDENT = names(nbcho), nbcho1 = nbcho)
    
# Etape 2 : fusionner eec et nbcho_df par IDENT
eec <- merge(eec, nbcho_df, by = "IDENT")
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

c. Utilisez habilement les noms de vecteur et l'opérateur `[` pour reproduire plus efficacement le résultat de la question b (toujours en repartant de `nbcho`). Vérifiez que la variable créée est bien identique. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# INDICATION : essayer de sélectionner par leur nom
# les valeurs de nbcho correspondant aux 10 premières observations
# de eec
    
# Le point essentiel est de remarquer que l'on peut
# utiliser les noms pour réarranger les valeurs
# de nbcho de sorte à ce qu'elles correspondent
# à l'ordre de eec
    
# Identifiant des 10 premières observations de eec
eec$IDENT[1:10]

# Pour extraire les valeurs de nbcho correspondantes,
# il suffit d'exploiter le fait que nbcho soit 
# nommé à l'aide des identifiants de ménage.

# Par exemple : 
# - Valeur de nbcho pour le premier ménage de eec
nbcho["G0A56JP6"] 
# - Valeur de nbcho pour les quatre premiers ménages
# de eec
nbcho[c("G0A56JP6", "G0A56JP6", "G0A56JR6", "G0A56JS6")]
# - Valeur de nbcho pour les 10 premiers ménages
# de eec
nbcho[eec$IDENT[1:10]]

# On peut donc par ce biais reconstituer l'intégralité 
# du vecteur correspondant aux observations de eec.
eec$nbcho2 <- nbcho[eec$IDENT]

# Ce vecteur est bien identique à celui obtenu par fusion
# à la question précédente.
all.equal(eec$nbcho1, eec$nbcho2)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

d. Comparez la syntaxe et les performances des méthodes mises en oeuvre aux question b. et c.

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# La syntaxe de la deuxième option est plus concise
# mais aussi plus complexe pour un relecteur moins
# averti des fonctionnalités de R en matière d'utilisation
# des noms de vecteur. 
    
# Comparaison des performances
microbenchmark(times = 10
  , merge1 = merge(eec, data.frame(IDENT = names(nbcho), nbcho1 = nbcho), by = "IDENT")
  , merge2 = merge(eec, nbcho_df, by = "IDENT")
  , names = nbcho[eec$IDENT]
)
# C'est sans commune mesure : que l'on tienne 
# compte (merge1) ou pas (merge2) de l'étape
# de constitution du data.frame, la méthode
# reposant sur les noms de vecteur est beaucoup
# plus rapide.
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

## Travailler efficacement sur des données avec `dplyr`

Les cas pratiques de cette partie reposent sur le *package* `dplyr` : 

```{r, eval = FALSE}
install.packages("dplyr")
library(dplyr)
```

```{r, include=FALSE}
library(dplyr)
```

Plusieurs vignettes sont disponibles sur la [page de documentation du *package*](https://CRAN.R-project.org/package=dplyr). Rstudio a également conçu un [aide-mémoire](https://www.rstudio.com/wp-content/uploads/2016/01/data-wrangling-french.pdf) (*cheatsheet*) traduit en français. **N'hésitez pas à vous référer à ces documents pour répondre aux cas pratiques de cette partie**.

```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("Sélection d'observations, de variables et tris")
```

a. Utilisez le verbe `filter()` pour afficher les observations des femmes (`SEXE == "2"`) actives occupées (`ACTEU == "1"`) en Île-de-France (`REG == "11"`). Utilisez la syntaxe classique puis celle faisant appel à l'opérateur *pipe* `%>%`. 


    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r, eval = FALSE}
# La fonction filter() permet de ne pas avoir à répéter
# le nom de la table et de pouvoir séparer les 
# différentes clauses par des ,
filter(eec, SEXE == "2", ACTEU == "1", REG == "11")
eec %>% filter(SEXE == "2", ACTEU == "1", REG == "11")
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

b. Utilisez le verbe `select()` pour supprimer toutes les variables créées à la sous-partie précédente (`trage1`, `trage2`, `trage3`, `trage4`, `nbcho1`, `nbcho2`). Pensez à consulter les exemples de l'aide de `select()` pour l'utiliser au mieux.

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# select() dispose de nombreuses fonctions outils
# pour simplement sélectionner (ou exclure avec -)
# des variables selon les caractères qu'elles contiennent.
eec %>% 
  select(-starts_with("trage"), -contains("nbcho")) -> 
  eec
# Note : utilisé à l'issue de plusieurs instruction, 
# l'opérateur `->` permet d'assigner des valeurs 
# à un objet situé à sa droite (et non à sa gauche comme `<-`)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

c. Utilisez le verbe `arrange()` pour trier la table par région et identifiant de ménage croissants puis par numéro d'ordre dans le ménage décroissants. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r, eval = FALSE}
# Il suffit d'indiquer la liste des variables sur
# lesquelles trier, éventuellement avec la fonction
# desc() quand l'ordre est décroissant.
eec %>% 
  arrange(REG, IDENT, desc(NOI)) -> 
  eec
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("Création de variables")
```

a. Utilisez le verbe `mutate()` pour effectuer le recodage en classes d'âge présenté lors de la partie précédente. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# mutate() est analogue à la fonction de base R
# transform() mais permet l'utilisation directe
# des variables créées dans le même appel de fonction.
eec %>% 
  mutate(
    age_num = as.numeric(AGE)
    , trage_dplyr = ifelse(age_num < 31, "15-30", ifelse(age_num < 61, "31-60", "61 et +"))
  ) ->
  eec
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

b. Comparez l'ergonomie et les performances de `mutate()` avec la méthode la plus efficace de base R. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# mutate() est relativement ergonomique dans la mesure
# où elle permet de ne pas répéter le nom de la table,
# de créer simultanément plusieurs variables et de 
# réutiliser immédiatement les variables créées.
    
# Comparaison des performances
microbenchmark(times = 100
  , base = {
    t <- as.numeric(eec$AGE)
    eec$trage4 <- "15-30"
    eec$trage4[t > 30 & t < 61] <- "31-60"
    eec$trage4[t > 60] <- "61 et +"
  }
  , dplyr = {
    eec %>% 
      mutate(
        age_num = as.numeric(AGE)
        , trage_dplyr = ifelse(age_num < 31, "15-30", ifelse(age_num < 61, "31-60", "61 et +"))
      ) ->
      eec
  }
)
    
# Le gain en termes d'ergonomie de mutate() a donc 
# un coût non-négligeable en termes de performances.
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```


```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("Agrégation par groupes : salaire moyen par région")
```

Comme dans le cas pratique correspondant de la partie précédente, l'objectif est d'estimer le salaire moyen par région, d'abord sans pondération puis pondéré par le poids de sondage `EXTRI1613`.

a. Utilisez la fonction `summarise()` pour calculer le salaire moyen non-pondéré et pondéré pour l'ensemble de la France métropolitaine. Intercalez ensuite la fonction `group_by()` pour ventiler ces calculs
par région.

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r, eval = FALSE}
# On commence par calculer les moyennes
# sur l'ensemble de la France métropolitaine
# grâce à la fonction summarise().
eec %>% 
  summarise(
    nonpond = mean(SALRED, na.rm = TRUE)
    , pond = weighted.mean(SALRED, EXTRI1613, na.rm = TRUE)
  )
    
# Pour ventiler les calculs par région, il suffit
# d'intercaler la fonction group_by()
eec %>% group_by(REG) %>%
  summarise(
    nonpond = mean(SALRED, na.rm = TRUE)
    , pond = weighted.mean(SALRED, EXTRI1613, na.rm = TRUE)
  )
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

b. Comparez l'ergonomie et les performances des fonctions de `dplyr` avec la méthode la plus efficace de base R. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# La syntaxe est beaucoup plus ergonomique avec
# les fonctions de dplyr, notamment du fait que
# la ventilation par une ou plusieurs variables
# ne nécessite qu'une adaptation minimale du code.

# Comparaison des performances
microbenchmark(times = 100
  , base = tapply(eec$SALRED, eec$REG, mean, na.rm = TRUE)
  , dplyr = eec %>% group_by(REG) %>% 
      summarise(SALRED = mean(SALRED, na.rm = TRUE))
)
# Ici dplyr est aussi rapide sinon plus que base R.
# On gagne donc sur tous les tableaux.
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```


```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("Fusion de tables : recodage de la PCS")
```

La variable `CSE` de la table `eec` code la Profession et catégorie socio-professionnelle (PCS) au niveau 3 de la nomenclature Insee (*cf.* le [site de l'Insee](https://www.insee.fr/fr/information/2497952)). On souhaite passer du niveau 3 au niveau 2. Le fichier `pcs2003_c_n4_n1.dbf` est la table de passage entre l'ensemble des niveaux de la nomenclature (de 1 à 4). 

a. Utilisez le *package* `foreign` et la fonction `read.dbf()` pour lire le fichier `pcs2003_c_n4_n1.dbf`. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# La fonction read.dbf() du package foreign
# permet de lire les fichier .dbf
library(foreign)
pcs <- read.dbf("pcs2003_c_n4_n1.dbf")
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

b. Utilisez le verbe `distinct()` pour restreindre la table aux observations distinctes pour les niveaux `N2` et `N3`. Créez également la variable `CSE`, version caractère de `N3`. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# Ces deux opérations peuvent être effectuées
# en une seule instruction avec des %>%
pcs %>% 
  distinct(N2, N3) %>% 
  mutate(CSE = as.character(N3)) ->
  pcs
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```
    
c. Utilisez le verbe `left_join()` pour fusionner la table `eec` avec la table de passage des PCS de niveau 3 à niveau 2. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# La syntaxe est rendue particulièrement claire 
# (et proche de SQL) par l'utilisation des %>%
eec %>% 
  left_join(pcs, by = "CSE") ->
  eec
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```
    
d. Une solution purement vectorielle en base R n'aurait-elle pas également été possible ? Comparez les performances de `dplyr` avec cette solution alternative. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# On aurait aussi pu réutiliser le mécanisme
# vu au cas pratique 13 en passant par un vecteur nommé
pcs2 <- setNames(pcs$N2, pcs$N3)
eec$N2_base <- pcs2[eec$CSE]
all.equal(eec$N2, eec$N2_base)

# Comparaison des performances
microbenchmark(times = 10
  , base = pcs2[eec$CSE]
  , dplyr = eec %>% left_join(pcs, by = "CSE")
)
# Il est possible que les perforamnces de la version 
# en base R soit affectées par le grand nombre de NA.
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```
    


## Travailler efficacement sur des données avec `data.table`

Les cas pratiques de cette partie reposent sur le *package* `data.table` : 

```{r, eval = FALSE}
install.packages("data.table")
library(data.table)
```

```{r, include=FALSE}
library(data.table)
```

On crée le `data.table` correspondant au `data.frame` `eec` : 
```{r}
eec_dt <- data.table(eec)
```

Plusieurs vignettes sont disponibles sur la [page de documentation du *package*](https://CRAN.R-project.org/package=data.table). **N'hésitez pas à vous référer à ces documents pour répondre aux cas pratiques de cette partie**.



```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("Sélection d'observations et tris")
```

a. Utilisez l'argument `i` de `[` pour afficher les observations des femmes (`SEXE == "2"`) actives occupées (`ACTEU == "1"`) en Île-de-France (`REG == "11"`). Quelle différence constatez-vous avec une sélection dans un `data.frame` ? 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r, eval = FALSE}
# Dans un data.frame et avec le [ de base R, 
# il est nécessaire de répéter le nom de la table
eec[eec$SEXE == "2" & eec$ACTEU == "1" & eec$REG == "11", ]
    
# Ce n'est pas le cas dans un data.table
eec_dt[SEXE == "2" & ACTEU == "1" & REG == "11", ]
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```


b. Utilisez la fonction `setkey()` pour faire de `SEXE`, `ACTEU` et `REG` des clés pour `eec_dt` et utilisez-les pour reproduire la sélection de la question précédente. Comparez alors l'ergonomie et les performances d'une sélection d'observations : 

    1. avec une clause logique dans un `data.frame` ;
    2. avec une clause logique en utilisant le verbe `filter()` de `dplyr` ;
    3. avec une clause logique dans un `data.table` ;
    4. avec un jeu de clés dans un `data.table`.
  

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r, eval = FALSE}
# La fonction setkey() permet de facilement créer
# des clés pour un data.table donné.
setkey(eec_dt, SEXE, ACTEU, REG)

# La sélection sur la base de clés s'effetue
# avec un argument sous la forme d'une liste
# DANS L'ORDRE DES CLES
eec_dt[list("2", "1", "11")]
    ```
    ```{r, include = FALSE}
setkey(eec_dt, SEXE, ACTEU, REG)
    ```
    ```{r}
# Comparaison des performances
microbenchmark(times = 100
  , base = eec[eec$SEXE == "2" & eec$ACTEU == "1" & eec$REG == "11", ]
  , dplyr = eec %>% filter(SEXE == "2", ACTEU == "1", REG == "11")
  , data.table1 = eec_dt[SEXE == "2" & ACTEU == "1" & REG == "11"]
  , data.table2 = eec_dt[list("2", "1", "11")]
)

# Les différentes version de data.table sont plus efficaces
# que base R et dplyr, en particulier quand il est fait
# usage des clés. 
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```


c. Utilisez la fonction `order()` (comme dans un `data.frame`) pour trier la table `eec_dt` par région et identifiant de ménage croissants puis par numéro d'ordre dans le ménage décroissants. Comparez les performances de base R, `arrange()` de `dplyr` et `data.table`. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# La principale différence avec la fonction order()
# appliquée à un data.frame est qu'il n'est pas 
# nécessaire de répéter le nom de la table et
# qu'il est possible d'utiliser le signe - devant 
# des variables caractère
eec_dt <- eec_dt[order(REG, IDENT, -NOI)]
    
# Comparaison des performances
microbenchmark(times = 10
  , base = eec[order(eec$REG, eec$IDENT, -as.numeric(eec$NOI)), ]
  , dplyr = eec %>% arrange(REG, IDENT, desc(NOI))
  , data.table = eec_dt[order(REG, IDENT, -NOI)]
)
# Le gain en termes de performances est sensible à nouveau.
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```


```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("Agrégation par groupes : salaire moyen par région")
```

Comme dans le cas pratiques correspondants des parties précédentes, on cherche à calculer le salaire moyen par région non-pondéré puis pondéré par le poids de sondage `EXTRI1613`.

a. Utilisez les arguments `j` et `by` de `[` pour calculer le salaire non-pondéré et pondéré d'abord sur l'ensemble de la France métropolitaine, puis par région. Comparez l'utilisation de `by` et `keyby` : pourquoi les résultats sont-ils ici identiques à votre avis ? 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# L'argument `j` de [ permet de créer de nouvelles 
# variables dans un data.table
eec_dt[, j = list(
  nonpond = mean(SALRED, na.rm = TRUE)
  , pond = weighted.mean(SALRED, EXTRI1613, na.rm = TRUE)
)]
# Pour ventiler par région, il suffit d'ajouter un argument by
eec_dt[, j = list(
  nonpond = mean(SALRED, na.rm = TRUE)
  , pond = weighted.mean(SALRED, EXTRI1613, na.rm = TRUE)
), by = REG]  
# Les résultats sont identiques ici selon que l'on utilise
# by ou keyby car les données sont triées par région.
# Si cela n'était pas le cas, by conserverait l'ordre du
# fichier (en affichant les groupes par ordre de rencontre)
# alors que keyby trierait les résultats par ordre
# alphabétique de région.
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

b. Comparez l'ergonomie et les performances de la solution en base R, avec `dplyr` et `data.table`. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# La solution en data.table est plus ergonomique que
# celle en base R, en particulier en raison de la
# facilité à ventiler les traitements par région. 
# Néanmoins, elle ne dispose pas de la capacité 
# à séquencer les traitements en petites opérations
# simples, ce que permet l'opérateur %>% qu'utilise
# intensément dplyr.
    
# Comparaison des performances
microbenchmark(times = 100
  , base = tapply(eec$SALRED, eec$REG, mean, na.rm = TRUE)
  , dplyr = eec %>% group_by(REG) %>% summarise(SALRED = mean(SALRED, na.rm = TRUE))
  , data.table = eec_dt[, j = list(mean(SALRED, na.rm = TRUE)), by = REG]
)
# Là encore data.table est beaucoup plus rapide.
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```


```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("Fusion de tables : nombre d'individus au chômage par ménage")
```

Comme dans le cas pratique 13, on cherche ici à associer à chaque individu le nombre d'individus au chômage (`ACTEU == "2"`) dans son ménage (individus avec la même valeur pour la variable `IDENT`). 

a. Utilisez les arguments `j` et `by` de `[` pour calculer le nombre d'individus au chômage par ménage. Utilisez la structure `j :=` pour automatiquement refusionner ce résultat avec la table de départ.  

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# On reprend la syntaxe de la question précédente
# pour calculer le nombre d'individu au chômage par ménage
eec_dt[, sum(ACTEU == "2", na.rm = TRUE), by = "IDENT"]
    
# Pour refusionner ces résultats avec la table d'origine,
# il suffit d'utiliser l'opérateur := au niveau de l'argument j
eec_dt <- eec_dt[, nbcho := sum(ACTEU == "2", na.rm = TRUE), by = "IDENT"]
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

b. Comment mèneriez vous ce traitement dans la logique de `dplyr` ? Comparez l'ergonomie et les performances de la solution en base R, `dplyr` et `data.table`. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# Avec dplyr, on serait tenté de fusionner la table eec
# avec une table de statistique (comme en base R)
eec %>% 
  left_join(
    eec %>% group_by(IDENT) %>% summarize(nbcho = n())
    , by = "IDENT"
  ) -> 
  eec

# Comparaison des performances
microbenchmark(times = 10
  , base = tapply(eec$ACTEU == "2", eec$IDENT, sum, na.rm = TRUE)[eec$IDENT]
  , dplyr = {
    eec %>% 
      left_join(
        eec %>% group_by(IDENT) %>% summarize(nbcho = n())
        , by = "IDENT"
      )
  }
  , data.table = eec_dt[, nbcho := sum(ACTEU == "2", na.rm = TRUE), by = "IDENT"]
)
# Comme toujours data.table est le plus rapide. 
# Néanmoins ici, il n'est pas à exclure qu'il existe
# dans dplyr une méthode plus efficace (une possibilité
# d'autofusion après agrégation par exemple). 
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```



## Réaliser des graphiques avec R

Les cas pratiques de cette partie reposent sur l'utilisation du *package* `ggplot2` :
```{r, eval = FALSE}
install.packages("ggplot2")
library(ggplot2)
```

```{r, include = FALSE}
library(ggplot2)
```

```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("Graphiques à partir de la table `mpg`")
```

L'objectif de ce cas pratique est de reproduire les graphiques du support ainsi que ceux présentés par H. Wickham dans le chapitre 2 de son ouvrage [ggplot2: Elegant Graphics for Data Analysis](https://github.com/hadley/ggplot2-book). 

Dans les deux cas, la table utilisée est `mpg` (table d'exemple du *package* `ggplot2`) : après avoir chargé `ggplot2`, utilisez la fonction `data()` pour "rapatrier" la table `mpg` dans l'environnement global et tapez `? mpg` pour obtenir une description détaillée de ses variables. En particulier : 

a. Utilisez les mots-clés `colour`, `shape` et `size` pour faire varier la représentation des points avec `geom_point()`. Pour chacun des mots-clés, comparez ce qu'il se passe quand vous utilisez une variable de type numérique ou une variable de type caractère ou facteur.
b. Comparez l'utilisation du mot-clé `colour` dans la fonction `aes()` et en dehors de la fonction `aes()`.
c. Testez les différents types de représentation possibles en les adaptant à la nature des données à représenter. Pour chaque fonction `geom_*()`, recherchez dans l'aide les paramètres qui lui sont spécifiques et testez des valeurs différentes de leurs valeurs par défaut.
d. Expérimentez les différentes possibilités de *facetting*.
e. Sauvegarder un graphique dans un objet R. Utilisez `ggsave()` pour exporter un graphique en `.png` et `.pdf`. 
f. Affichez le code d'une fonction `geom_*()` et utilisez ces informations pour reconstituer manuellement l'instruction `layer()` correspondante.
g. Tentez de reproduire un graphique standard de `ggplot2` avec les fonctions du *package* `graphics`.


```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("Graphiques à partir de la table `diamonds`")
```

La table `diamonds` est le second fichier de démonstration classique de `ggplot2` : utilisez `data()` pour le "rapatrier" dans l'environnement global et tapez `? diamonds` pour obtenir une description détaillée de ses variables.

a. Représentez la relation entre poids du diamant (`carat`) et prix (`price`). Utilisez le paramètre `alpha` pour limiter la saturation du graphique par le très grand nombre de points. Ajoutez une droite de régression linéaire au graphique.

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r, dev="png"}
# Par défaut, les points sont totalement opaques : 
# on ne peut pas visualiser les points qui se superposent
# les uns aux autres (on parle d'over-plotting)
ggplot(diamonds, aes(carat, price)) + geom_point()
    
# Le paramètre alpha indique de rendre les points
# en partie transparent. Avec alpha = 0.05, il faut
# 20 points pour obtenir une zone totalement opaque
ggplot(diamonds, aes(carat, price)) + geom_point(alpha = 0.05)

# Pour ajouter une droite de régression, il suffit 
# d'utiliser la fonction geom_smooth() avec l'option
# method = "lm"
ggplot(diamonds, aes(carat, price)) + geom_point(alpha = 0.05) + 
  geom_smooth(method = "lm")
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

b. Représentez l'influence de la couleur (`color`) sur le prix de plusieurs manières.

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r, dev="png"}
# Idée 1 : faire varier la couleur des points 
# sur le graph précédent
g1 <- ggplot(diamonds, aes(carat, price, colour = color)) + geom_point(alpha = 0.05)
g1

# Il est possible d'améliorer le graphique précédent
# 1) en ajustant la manière dont les couleurs sont représentées 
# dans la légende
g1 <- g1 + guides(colour = guide_legend(override.aes = list(alpha = 1)))
g1

# 2) en adoptant une palette de couleurs formant un gradient
# (car la variable color est ordonnée de la pire (J) à la 
# meilleure (D))
g1 <- g1 + scale_colour_brewer(palette = 1)
g1

# Idée 2 : dessiner des boîtes à moustaches
g2 <- ggplot(diamonds, aes(color, price)) + geom_boxplot(varwidth = TRUE)
g2
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

c. Représentez la ventilation des diamants selon la qualité de leur taille (`cut`) et leur clarté (`clarity`). 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r, dev="png"}
# Le plus simple est de représenter l'histogramme bivarié
ggplot(diamonds, aes(clarity, fill = cut)) + geom_bar()

# Quelques variations sur le positionnement des blocs
ggplot(diamonds, aes(clarity, fill = cut)) + geom_bar(position = "dodge")
ggplot(diamonds, aes(clarity, fill = cut)) + geom_bar(position = "fill")
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```


d. Vérifiez graphiquement si la relation entre poids et prix ne varie pas en fonction de la qualité de la taille (`cut`) et la clarté du diamant (`clarity`). 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r, dev="png"}
# L'idée ici est d'utiliser le facetting pour ventiler
# le premier graphique par qualité de la taille et clarté 
g3 <- ggplot(diamonds, aes(carat, price)) + geom_smooth() +
      facet_grid(cut ~ clarity)
g3
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```




```{r, results = "asis", echo = FALSE, cache=FALSE}
.question("Graphiques à partir de la table `raisin`")
```

Le fichier `raisin.rds` comporte des informations sur la maturation du raisin dans des exploitations viticoles de Saône-et-Loire sur la période 2000-2012. 

a. Chargez ce fichier en mémoire avec la fonction `readRDS()` et analysez les caractéristiques des variables de ce fichier (modalités, distributions, etc.).

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# Chargement en mémoire du fichier raisin.rds
# situé dans le répertoire de travail
raisin <- readRDS("raisin.rds")
    
# Caractéristiques des variables de raisin
table(raisin$annee)
table(raisin$secteur)
table(raisin$cepage)
table(raisin$commune)
summary(raisin)
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

b. Analysez la fréquence des différents cépages en fonction du temps. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# Le plus simple est ici de faire un diagramme en bâton
# en fonction du temps
ggplot(raisin, aes(annee, fill = cepage)) + geom_bar()

# On peut utiliser explicitement la statistique "count"
# associée par défaut à geom_bar() (tapez geom_bar pour
# le vérifier) à d'autres fonctions pour modifier cette
# représentation
ggplot(raisin, aes(annee, colour = cepage)) + geom_line(stat = "count")
ggplot(raisin, aes(annee, fill = cepage)) + geom_area(stat = "count")
    ```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```

c. Analysez graphiquement la relation entre `sucres` et `acidite_totale`. Utilisez d'autres variables pour tenter de rendre compte de cette distribution. 

    ```{r, results = "asis", echo = FALSE}
.beginsol()
    ```
    ```{r}
# On utilise tout simplement un nuage de points pour représenter
# ces deux variables quantitatives
ggplot(raisin, aes(sucres, acidite_totale)) + geom_point()
    
# On perçoit très nettement deux groupes : sont-ils expliqués
# par le secteur ou le cépage ? 
ggplot(raisin, aes(sucres, acidite_totale, colour = cepage)) + geom_point()
ggplot(raisin, aes(sucres, acidite_totale, colour = secteur)) + geom_point()

# Pour confirmer et ne pas se laisser abuser
# par la superposition de certains points, on 
# utilise le facetting
ggplot(raisin, aes(sucres, acidite_totale)) + geom_point() + 
  facet_wrap(~cepage)
ggplot(raisin, aes(sucres, acidite_totale)) + geom_point() + 
  facet_wrap(~secteur)
ggplot(raisin, aes(sucres, acidite_totale)) + geom_point() + 
  facet_grid(cepage~secteur)
# Il apparaît clairement que c'est la localisation dans le
# maconnais ou les cépages chardonnay et gamay qui lui
# sont spécifiques (au sein de la Saône-et-Loire) qui 
# semblent expliquer l'oscillation entre deux types de relations
# entre sucres et acidité totale. 

# Peut-être cette oscillation dépend-elle des années ? 
ggplot(raisin[raisin$secteur == "Maconnais", ], aes(sucres, acidite_totale, colour = as.factor(annee))) + geom_point()

# Ce n'est pas évident, à nouveau on utilise le facetting
ggplot(raisin[raisin$secteur == "Maconnais", ], aes(sucres, acidite_totale, colour = commune)) + geom_point() + facet_wrap(~annee)
# Le raisin du secteur du maconnais, quel que soit sa commune, 
# semble présenter un profil sucres-acidite_totale particulier
# de 2000 à 2003 (plus sucré).
```
    ```{r, results = "asis", echo = FALSE}
.endsol()
    ```
